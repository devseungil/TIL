{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX1jWqA0WvcpXm1D44HPX/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TEPqKV_2QCtK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "(train_img , train_labels) , (test_img , test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Aaw2hHpQDc0",
        "outputId": "f840fc1e-b2e2-4b86-c71d-a4bde794a199"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = keras.utils.to_categorical(train_labels.astype('int32'), 10)\n",
        "test_labels = keras.utils.to_categorical(test_labels.astype('int32'), 10)"
      ],
      "metadata": {
        "id": "AncuO2QAQL3t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img = train_img.reshape(train_img.shape[0],28,28,1)\n",
        "test_img = test_img.reshape(test_img.shape[0],28,28,1)\n",
        "print(train_img.shape)\n",
        "#정수형 이미지 데이터를 float 형 변환\n",
        "train_img = train_img.astype('float32')\n",
        "test_img = test_img.astype('float32')\n",
        "\n",
        "#학습을 위해서 0 ~ 255 - > 0 ~ 1.0 범위로 지정 255로 나눈다\n",
        "train_img = train_img / 255\n",
        "test_img = test_img / 255\n",
        "test_img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjImYqHHQOAE",
        "outputId": "19e2e3fa-b05e-40f8-9b6e-0ac4c57a346f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img = np.transpose(train_img, [0,3,1,2])\n",
        "test_img = np.transpose(test_img, [0,3,1,2])"
      ],
      "metadata": {
        "id": "IxGZQH5pQPH7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D , Dense, Flatten , Activation\n",
        "# CNN 모형 만들기\n",
        "# data_format은 컨볼루젼이랑 맥스풀링이랑 맞춰줘야함\n",
        "\n",
        "model_cnn = Sequential()\n",
        "# layer 0\n",
        "model_cnn.add(Conv2D(\n",
        "    5,\n",
        "    kernel_size=(4,4),\n",
        "    strides=(1, 1),\n",
        "    padding='valid',\n",
        "    data_format='channels_first',\n",
        "    dilation_rate=(1, 1),\n",
        "    groups=1,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='ones', # zeros -> ones\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    name='conv1'))\n",
        "# layer 1\n",
        "model_cnn.add(MaxPool2D(\n",
        "    pool_size=(2, 2),\n",
        "    strides=(2, 2),\n",
        "    padding='same',\n",
        "    data_format='channels_first',\n",
        "    name='maxpool1'))\n",
        "#layer 2\n",
        "model_cnn.add(Activation('tanh')) # 컨볼루젼에서는 탄젠트 많이쓰임\n",
        "\n",
        "# layer3\n",
        "model_cnn.add(Conv2D(\n",
        "    3,\n",
        "    kernel_size=(3,3),\n",
        "    strides=(1, 1),\n",
        "    padding='valid',\n",
        "    data_format='channels_first',\n",
        "    dilation_rate=(1, 1),\n",
        "    groups=1,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='ones', # zeros -> ones\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    name='conv2'))\n",
        "# layer 4\n",
        "model_cnn.add(MaxPool2D(\n",
        "    pool_size=(2, 2),\n",
        "    strides=(2, 2),\n",
        "    padding='same',\n",
        "    data_format='channels_first',\n",
        "    name='maxpool2'))\n",
        "#layer 5\n",
        "model_cnn.add(Activation('tanh'))\n",
        "\n",
        "# layer6\n",
        "model_cnn.add(Conv2D(\n",
        "    3,\n",
        "    kernel_size=(4,4),\n",
        "    strides=(1, 1),\n",
        "    padding='valid',\n",
        "    data_format='channels_first',\n",
        "    dilation_rate=(1, 1),\n",
        "    groups=1,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='ones', # zeros -> ones\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    name='conv3'\n",
        "))\n",
        "# layer 7\n",
        "model_cnn.add(Activation('tanh')) # 컨볼루젼 끝내기\n",
        "\n",
        "# layer 8\n",
        "model_cnn.add(Flatten(data_format=None , name = 'flat1'))\n",
        "# layer 9 \n",
        "model_cnn.add(Dense(10, use_bias=True,bias_initializer='ones', name = 'dense1' ))\n",
        "# layer 10\n",
        "model_cnn.add(Activation('softmax'))\n"
      ],
      "metadata": {
        "id": "CT_my5CiQQoz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.compile(tf.keras.optimizers.Adam() , 'categorical_crossentropy' , ['acc'])"
      ],
      "metadata": {
        "id": "OdszmetPQTAT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model_cnn.fit(train_img , train_labels , epochs=500 , batch_size=64 , validation_data = (test_img,test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbfn-cw1QUu7",
        "outputId": "6687d547-522a-4222-9080-e9945aa4ecda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "938/938 [==============================] - 17s 6ms/step - loss: 1.2066 - acc: 0.6089 - val_loss: 0.4502 - val_acc: 0.8768\n",
            "Epoch 2/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.3758 - acc: 0.8923 - val_loss: 0.2865 - val_acc: 0.9216\n",
            "Epoch 3/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2758 - acc: 0.9195 - val_loss: 0.2234 - val_acc: 0.9350\n",
            "Epoch 4/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.2300 - acc: 0.9314 - val_loss: 0.1933 - val_acc: 0.9450\n",
            "Epoch 5/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2031 - acc: 0.9397 - val_loss: 0.1753 - val_acc: 0.9488\n",
            "Epoch 6/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1852 - acc: 0.9450 - val_loss: 0.1591 - val_acc: 0.9526\n",
            "Epoch 7/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1721 - acc: 0.9484 - val_loss: 0.1529 - val_acc: 0.9536\n",
            "Epoch 8/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1623 - acc: 0.9512 - val_loss: 0.1456 - val_acc: 0.9559\n",
            "Epoch 9/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1549 - acc: 0.9531 - val_loss: 0.1396 - val_acc: 0.9576\n",
            "Epoch 10/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1480 - acc: 0.9549 - val_loss: 0.1381 - val_acc: 0.9559\n",
            "Epoch 11/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1433 - acc: 0.9564 - val_loss: 0.1373 - val_acc: 0.9577\n",
            "Epoch 12/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1391 - acc: 0.9575 - val_loss: 0.1256 - val_acc: 0.9610\n",
            "Epoch 13/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.1350 - acc: 0.9585 - val_loss: 0.1242 - val_acc: 0.9614\n",
            "Epoch 14/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.1324 - acc: 0.9593 - val_loss: 0.1232 - val_acc: 0.9616\n",
            "Epoch 15/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1286 - acc: 0.9605 - val_loss: 0.1211 - val_acc: 0.9620\n",
            "Epoch 16/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1261 - acc: 0.9611 - val_loss: 0.1245 - val_acc: 0.9602\n",
            "Epoch 17/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1235 - acc: 0.9620 - val_loss: 0.1146 - val_acc: 0.9637\n",
            "Epoch 18/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1218 - acc: 0.9618 - val_loss: 0.1188 - val_acc: 0.9640\n",
            "Epoch 19/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1194 - acc: 0.9632 - val_loss: 0.1119 - val_acc: 0.9652\n",
            "Epoch 20/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1181 - acc: 0.9634 - val_loss: 0.1107 - val_acc: 0.9650\n",
            "Epoch 21/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1163 - acc: 0.9646 - val_loss: 0.1116 - val_acc: 0.9659\n",
            "Epoch 22/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1141 - acc: 0.9650 - val_loss: 0.1145 - val_acc: 0.9623\n",
            "Epoch 23/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.1131 - acc: 0.9653 - val_loss: 0.1069 - val_acc: 0.9660\n",
            "Epoch 24/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1114 - acc: 0.9658 - val_loss: 0.1076 - val_acc: 0.9662\n",
            "Epoch 25/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.1096 - acc: 0.9661 - val_loss: 0.1069 - val_acc: 0.9655\n",
            "Epoch 26/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1086 - acc: 0.9668 - val_loss: 0.1063 - val_acc: 0.9659\n",
            "Epoch 27/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1071 - acc: 0.9671 - val_loss: 0.1067 - val_acc: 0.9662\n",
            "Epoch 28/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1064 - acc: 0.9672 - val_loss: 0.1051 - val_acc: 0.9663\n",
            "Epoch 29/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1053 - acc: 0.9678 - val_loss: 0.1070 - val_acc: 0.9663\n",
            "Epoch 30/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1043 - acc: 0.9686 - val_loss: 0.0990 - val_acc: 0.9683\n",
            "Epoch 31/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1038 - acc: 0.9678 - val_loss: 0.1027 - val_acc: 0.9673\n",
            "Epoch 32/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1033 - acc: 0.9686 - val_loss: 0.0981 - val_acc: 0.9699\n",
            "Epoch 33/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.1017 - acc: 0.9687 - val_loss: 0.0987 - val_acc: 0.9678\n",
            "Epoch 34/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1010 - acc: 0.9693 - val_loss: 0.0992 - val_acc: 0.9690\n",
            "Epoch 35/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.1004 - acc: 0.9690 - val_loss: 0.0947 - val_acc: 0.9703\n",
            "Epoch 36/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0995 - acc: 0.9697 - val_loss: 0.0988 - val_acc: 0.9691\n",
            "Epoch 37/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0987 - acc: 0.9693 - val_loss: 0.1020 - val_acc: 0.9692\n",
            "Epoch 38/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0984 - acc: 0.9696 - val_loss: 0.0987 - val_acc: 0.9694\n",
            "Epoch 39/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0976 - acc: 0.9701 - val_loss: 0.0917 - val_acc: 0.9716\n",
            "Epoch 40/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0969 - acc: 0.9699 - val_loss: 0.0919 - val_acc: 0.9703\n",
            "Epoch 41/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0967 - acc: 0.9703 - val_loss: 0.0917 - val_acc: 0.9724\n",
            "Epoch 42/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0960 - acc: 0.9705 - val_loss: 0.0985 - val_acc: 0.9704\n",
            "Epoch 43/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0950 - acc: 0.9713 - val_loss: 0.0976 - val_acc: 0.9693\n",
            "Epoch 44/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0946 - acc: 0.9707 - val_loss: 0.0950 - val_acc: 0.9706\n",
            "Epoch 45/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0939 - acc: 0.9707 - val_loss: 0.0896 - val_acc: 0.9719\n",
            "Epoch 46/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0935 - acc: 0.9706 - val_loss: 0.0933 - val_acc: 0.9704\n",
            "Epoch 47/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0933 - acc: 0.9713 - val_loss: 0.0883 - val_acc: 0.9719\n",
            "Epoch 48/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0929 - acc: 0.9715 - val_loss: 0.0917 - val_acc: 0.9711\n",
            "Epoch 49/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0930 - acc: 0.9715 - val_loss: 0.0894 - val_acc: 0.9723\n",
            "Epoch 50/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0920 - acc: 0.9713 - val_loss: 0.0879 - val_acc: 0.9727\n",
            "Epoch 51/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0921 - acc: 0.9713 - val_loss: 0.0905 - val_acc: 0.9714\n",
            "Epoch 52/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0916 - acc: 0.9715 - val_loss: 0.0888 - val_acc: 0.9709\n",
            "Epoch 53/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0904 - acc: 0.9722 - val_loss: 0.0889 - val_acc: 0.9722\n",
            "Epoch 54/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0900 - acc: 0.9722 - val_loss: 0.0907 - val_acc: 0.9722\n",
            "Epoch 55/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0902 - acc: 0.9722 - val_loss: 0.0910 - val_acc: 0.9724\n",
            "Epoch 56/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0897 - acc: 0.9721 - val_loss: 0.0851 - val_acc: 0.9731\n",
            "Epoch 57/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0891 - acc: 0.9723 - val_loss: 0.0923 - val_acc: 0.9714\n",
            "Epoch 58/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0886 - acc: 0.9725 - val_loss: 0.0869 - val_acc: 0.9732\n",
            "Epoch 59/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0887 - acc: 0.9721 - val_loss: 0.0866 - val_acc: 0.9727\n",
            "Epoch 60/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0879 - acc: 0.9725 - val_loss: 0.0847 - val_acc: 0.9752\n",
            "Epoch 61/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0878 - acc: 0.9727 - val_loss: 0.0894 - val_acc: 0.9715\n",
            "Epoch 62/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0880 - acc: 0.9728 - val_loss: 0.0836 - val_acc: 0.9741\n",
            "Epoch 63/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0873 - acc: 0.9733 - val_loss: 0.0880 - val_acc: 0.9726\n",
            "Epoch 64/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0877 - acc: 0.9729 - val_loss: 0.0840 - val_acc: 0.9749\n",
            "Epoch 65/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0871 - acc: 0.9729 - val_loss: 0.0924 - val_acc: 0.9719\n",
            "Epoch 66/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0861 - acc: 0.9733 - val_loss: 0.0915 - val_acc: 0.9711\n",
            "Epoch 67/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0866 - acc: 0.9730 - val_loss: 0.0879 - val_acc: 0.9733\n",
            "Epoch 68/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0858 - acc: 0.9736 - val_loss: 0.0853 - val_acc: 0.9733\n",
            "Epoch 69/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0863 - acc: 0.9733 - val_loss: 0.0851 - val_acc: 0.9733\n",
            "Epoch 70/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0858 - acc: 0.9733 - val_loss: 0.0870 - val_acc: 0.9732\n",
            "Epoch 71/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0856 - acc: 0.9738 - val_loss: 0.0854 - val_acc: 0.9737\n",
            "Epoch 72/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0850 - acc: 0.9735 - val_loss: 0.0841 - val_acc: 0.9749\n",
            "Epoch 73/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0849 - acc: 0.9734 - val_loss: 0.0854 - val_acc: 0.9732\n",
            "Epoch 74/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0845 - acc: 0.9742 - val_loss: 0.0817 - val_acc: 0.9753\n",
            "Epoch 75/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0852 - acc: 0.9736 - val_loss: 0.0825 - val_acc: 0.9754\n",
            "Epoch 76/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0846 - acc: 0.9737 - val_loss: 0.0806 - val_acc: 0.9748\n",
            "Epoch 77/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0841 - acc: 0.9735 - val_loss: 0.0821 - val_acc: 0.9754\n",
            "Epoch 78/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0841 - acc: 0.9736 - val_loss: 0.0816 - val_acc: 0.9754\n",
            "Epoch 79/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0838 - acc: 0.9741 - val_loss: 0.0833 - val_acc: 0.9748\n",
            "Epoch 80/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0835 - acc: 0.9738 - val_loss: 0.0798 - val_acc: 0.9766\n",
            "Epoch 81/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0836 - acc: 0.9740 - val_loss: 0.0826 - val_acc: 0.9748\n",
            "Epoch 82/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0828 - acc: 0.9744 - val_loss: 0.0849 - val_acc: 0.9739\n",
            "Epoch 83/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0836 - acc: 0.9737 - val_loss: 0.0883 - val_acc: 0.9726\n",
            "Epoch 84/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0833 - acc: 0.9740 - val_loss: 0.0852 - val_acc: 0.9733\n",
            "Epoch 85/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0821 - acc: 0.9748 - val_loss: 0.0827 - val_acc: 0.9758\n",
            "Epoch 86/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0827 - acc: 0.9740 - val_loss: 0.0838 - val_acc: 0.9750\n",
            "Epoch 87/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0826 - acc: 0.9741 - val_loss: 0.0818 - val_acc: 0.9756\n",
            "Epoch 88/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0828 - acc: 0.9742 - val_loss: 0.0819 - val_acc: 0.9745\n",
            "Epoch 89/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0822 - acc: 0.9742 - val_loss: 0.0821 - val_acc: 0.9744\n",
            "Epoch 90/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0821 - acc: 0.9744 - val_loss: 0.0809 - val_acc: 0.9749\n",
            "Epoch 91/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0826 - acc: 0.9738 - val_loss: 0.0791 - val_acc: 0.9763\n",
            "Epoch 92/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0822 - acc: 0.9749 - val_loss: 0.0801 - val_acc: 0.9764\n",
            "Epoch 93/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0826 - acc: 0.9739 - val_loss: 0.0823 - val_acc: 0.9753\n",
            "Epoch 94/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0824 - acc: 0.9745 - val_loss: 0.0806 - val_acc: 0.9762\n",
            "Epoch 95/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0817 - acc: 0.9747 - val_loss: 0.0786 - val_acc: 0.9762\n",
            "Epoch 96/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0811 - acc: 0.9750 - val_loss: 0.0811 - val_acc: 0.9754\n",
            "Epoch 97/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0815 - acc: 0.9743 - val_loss: 0.0839 - val_acc: 0.9735\n",
            "Epoch 98/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0810 - acc: 0.9747 - val_loss: 0.0822 - val_acc: 0.9756\n",
            "Epoch 99/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0810 - acc: 0.9748 - val_loss: 0.0839 - val_acc: 0.9745\n",
            "Epoch 100/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0811 - acc: 0.9744 - val_loss: 0.0819 - val_acc: 0.9737\n",
            "Epoch 101/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0808 - acc: 0.9746 - val_loss: 0.0829 - val_acc: 0.9752\n",
            "Epoch 102/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0807 - acc: 0.9747 - val_loss: 0.0884 - val_acc: 0.9730\n",
            "Epoch 103/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0806 - acc: 0.9745 - val_loss: 0.0814 - val_acc: 0.9745\n",
            "Epoch 104/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0805 - acc: 0.9744 - val_loss: 0.0811 - val_acc: 0.9753\n",
            "Epoch 105/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0804 - acc: 0.9750 - val_loss: 0.0826 - val_acc: 0.9743\n",
            "Epoch 106/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0798 - acc: 0.9751 - val_loss: 0.0793 - val_acc: 0.9764\n",
            "Epoch 107/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0805 - acc: 0.9747 - val_loss: 0.0811 - val_acc: 0.9748\n",
            "Epoch 108/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0801 - acc: 0.9751 - val_loss: 0.0808 - val_acc: 0.9752\n",
            "Epoch 109/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0800 - acc: 0.9752 - val_loss: 0.0835 - val_acc: 0.9744\n",
            "Epoch 110/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0791 - acc: 0.9754 - val_loss: 0.0832 - val_acc: 0.9755\n",
            "Epoch 111/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0797 - acc: 0.9754 - val_loss: 0.0855 - val_acc: 0.9734\n",
            "Epoch 112/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0798 - acc: 0.9754 - val_loss: 0.0796 - val_acc: 0.9765\n",
            "Epoch 113/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0797 - acc: 0.9753 - val_loss: 0.0823 - val_acc: 0.9741\n",
            "Epoch 114/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0795 - acc: 0.9757 - val_loss: 0.0808 - val_acc: 0.9750\n",
            "Epoch 115/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0793 - acc: 0.9751 - val_loss: 0.0772 - val_acc: 0.9770\n",
            "Epoch 116/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0790 - acc: 0.9756 - val_loss: 0.0833 - val_acc: 0.9738\n",
            "Epoch 117/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0790 - acc: 0.9750 - val_loss: 0.0788 - val_acc: 0.9759\n",
            "Epoch 118/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0794 - acc: 0.9750 - val_loss: 0.0830 - val_acc: 0.9748\n",
            "Epoch 119/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0785 - acc: 0.9753 - val_loss: 0.0778 - val_acc: 0.9771\n",
            "Epoch 120/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0787 - acc: 0.9753 - val_loss: 0.0754 - val_acc: 0.9766\n",
            "Epoch 121/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0784 - acc: 0.9753 - val_loss: 0.0804 - val_acc: 0.9753\n",
            "Epoch 122/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0790 - acc: 0.9754 - val_loss: 0.0755 - val_acc: 0.9771\n",
            "Epoch 123/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0787 - acc: 0.9757 - val_loss: 0.0790 - val_acc: 0.9768\n",
            "Epoch 124/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0786 - acc: 0.9756 - val_loss: 0.0791 - val_acc: 0.9757\n",
            "Epoch 125/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0782 - acc: 0.9754 - val_loss: 0.0779 - val_acc: 0.9765\n",
            "Epoch 126/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0782 - acc: 0.9757 - val_loss: 0.0824 - val_acc: 0.9746\n",
            "Epoch 127/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0782 - acc: 0.9758 - val_loss: 0.0792 - val_acc: 0.9752\n",
            "Epoch 128/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0778 - acc: 0.9760 - val_loss: 0.0814 - val_acc: 0.9747\n",
            "Epoch 129/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0786 - acc: 0.9755 - val_loss: 0.0757 - val_acc: 0.9772\n",
            "Epoch 130/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0772 - acc: 0.9759 - val_loss: 0.0767 - val_acc: 0.9763\n",
            "Epoch 131/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0774 - acc: 0.9757 - val_loss: 0.0797 - val_acc: 0.9754\n",
            "Epoch 132/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0772 - acc: 0.9757 - val_loss: 0.0771 - val_acc: 0.9768\n",
            "Epoch 133/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0774 - acc: 0.9759 - val_loss: 0.0832 - val_acc: 0.9741\n",
            "Epoch 134/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0775 - acc: 0.9758 - val_loss: 0.0763 - val_acc: 0.9770\n",
            "Epoch 135/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0768 - acc: 0.9758 - val_loss: 0.0776 - val_acc: 0.9762\n",
            "Epoch 136/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0769 - acc: 0.9759 - val_loss: 0.0787 - val_acc: 0.9763\n",
            "Epoch 137/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0769 - acc: 0.9759 - val_loss: 0.0806 - val_acc: 0.9760\n",
            "Epoch 138/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0773 - acc: 0.9757 - val_loss: 0.0768 - val_acc: 0.9761\n",
            "Epoch 139/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0773 - acc: 0.9756 - val_loss: 0.0767 - val_acc: 0.9767\n",
            "Epoch 140/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0773 - acc: 0.9760 - val_loss: 0.0763 - val_acc: 0.9767\n",
            "Epoch 141/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0769 - acc: 0.9761 - val_loss: 0.0790 - val_acc: 0.9753\n",
            "Epoch 142/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0769 - acc: 0.9756 - val_loss: 0.0756 - val_acc: 0.9771\n",
            "Epoch 143/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0764 - acc: 0.9761 - val_loss: 0.0763 - val_acc: 0.9769\n",
            "Epoch 144/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0764 - acc: 0.9762 - val_loss: 0.0795 - val_acc: 0.9757\n",
            "Epoch 145/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0760 - acc: 0.9761 - val_loss: 0.0742 - val_acc: 0.9776\n",
            "Epoch 146/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0754 - acc: 0.9764 - val_loss: 0.0789 - val_acc: 0.9763\n",
            "Epoch 147/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0764 - acc: 0.9764 - val_loss: 0.0765 - val_acc: 0.9771\n",
            "Epoch 148/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0756 - acc: 0.9764 - val_loss: 0.0747 - val_acc: 0.9775\n",
            "Epoch 149/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0760 - acc: 0.9764 - val_loss: 0.0781 - val_acc: 0.9764\n",
            "Epoch 150/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0761 - acc: 0.9762 - val_loss: 0.0763 - val_acc: 0.9768\n",
            "Epoch 151/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0761 - acc: 0.9761 - val_loss: 0.0757 - val_acc: 0.9762\n",
            "Epoch 152/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0758 - acc: 0.9763 - val_loss: 0.0754 - val_acc: 0.9775\n",
            "Epoch 153/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0758 - acc: 0.9764 - val_loss: 0.0743 - val_acc: 0.9777\n",
            "Epoch 154/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0756 - acc: 0.9763 - val_loss: 0.0745 - val_acc: 0.9777\n",
            "Epoch 155/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0756 - acc: 0.9760 - val_loss: 0.0806 - val_acc: 0.9753\n",
            "Epoch 156/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0757 - acc: 0.9760 - val_loss: 0.0793 - val_acc: 0.9762\n",
            "Epoch 157/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0754 - acc: 0.9765 - val_loss: 0.0756 - val_acc: 0.9779\n",
            "Epoch 158/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0759 - acc: 0.9761 - val_loss: 0.0800 - val_acc: 0.9754\n",
            "Epoch 159/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0755 - acc: 0.9761 - val_loss: 0.0762 - val_acc: 0.9772\n",
            "Epoch 160/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0755 - acc: 0.9764 - val_loss: 0.0736 - val_acc: 0.9773\n",
            "Epoch 161/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0748 - acc: 0.9763 - val_loss: 0.0754 - val_acc: 0.9767\n",
            "Epoch 162/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0749 - acc: 0.9764 - val_loss: 0.0842 - val_acc: 0.9740\n",
            "Epoch 163/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0759 - acc: 0.9757 - val_loss: 0.0751 - val_acc: 0.9770\n",
            "Epoch 164/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0751 - acc: 0.9767 - val_loss: 0.0780 - val_acc: 0.9759\n",
            "Epoch 165/500\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0746 - acc: 0.9769 - val_loss: 0.0739 - val_acc: 0.9782\n",
            "Epoch 166/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0757 - acc: 0.9763 - val_loss: 0.0765 - val_acc: 0.9766\n",
            "Epoch 167/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0752 - acc: 0.9762 - val_loss: 0.0758 - val_acc: 0.9778\n",
            "Epoch 168/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0747 - acc: 0.9767 - val_loss: 0.0730 - val_acc: 0.9778\n",
            "Epoch 169/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0749 - acc: 0.9763 - val_loss: 0.0782 - val_acc: 0.9770\n",
            "Epoch 170/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0747 - acc: 0.9765 - val_loss: 0.0803 - val_acc: 0.9755\n",
            "Epoch 171/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0752 - acc: 0.9762 - val_loss: 0.0715 - val_acc: 0.9777\n",
            "Epoch 172/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0743 - acc: 0.9776 - val_loss: 0.0741 - val_acc: 0.9767\n",
            "Epoch 173/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0741 - acc: 0.9768 - val_loss: 0.0775 - val_acc: 0.9779\n",
            "Epoch 174/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0743 - acc: 0.9767 - val_loss: 0.0760 - val_acc: 0.9765\n",
            "Epoch 175/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0738 - acc: 0.9768 - val_loss: 0.0729 - val_acc: 0.9782\n",
            "Epoch 176/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0744 - acc: 0.9764 - val_loss: 0.0739 - val_acc: 0.9773\n",
            "Epoch 177/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0745 - acc: 0.9766 - val_loss: 0.0724 - val_acc: 0.9783\n",
            "Epoch 178/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0744 - acc: 0.9768 - val_loss: 0.0728 - val_acc: 0.9785\n",
            "Epoch 179/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0743 - acc: 0.9771 - val_loss: 0.0748 - val_acc: 0.9771\n",
            "Epoch 180/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0744 - acc: 0.9768 - val_loss: 0.0741 - val_acc: 0.9777\n",
            "Epoch 181/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0743 - acc: 0.9766 - val_loss: 0.0748 - val_acc: 0.9773\n",
            "Epoch 182/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0737 - acc: 0.9767 - val_loss: 0.0718 - val_acc: 0.9785\n",
            "Epoch 183/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0746 - acc: 0.9765 - val_loss: 0.0715 - val_acc: 0.9774\n",
            "Epoch 184/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0740 - acc: 0.9770 - val_loss: 0.0726 - val_acc: 0.9778\n",
            "Epoch 185/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0739 - acc: 0.9771 - val_loss: 0.0734 - val_acc: 0.9780\n",
            "Epoch 186/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0736 - acc: 0.9772 - val_loss: 0.0717 - val_acc: 0.9781\n",
            "Epoch 187/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0742 - acc: 0.9767 - val_loss: 0.0735 - val_acc: 0.9774\n",
            "Epoch 188/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0737 - acc: 0.9765 - val_loss: 0.0719 - val_acc: 0.9780\n",
            "Epoch 189/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0739 - acc: 0.9766 - val_loss: 0.0734 - val_acc: 0.9780\n",
            "Epoch 190/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0742 - acc: 0.9762 - val_loss: 0.0740 - val_acc: 0.9773\n",
            "Epoch 191/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0732 - acc: 0.9771 - val_loss: 0.0733 - val_acc: 0.9778\n",
            "Epoch 192/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0733 - acc: 0.9771 - val_loss: 0.0743 - val_acc: 0.9776\n",
            "Epoch 193/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0736 - acc: 0.9767 - val_loss: 0.0701 - val_acc: 0.9785\n",
            "Epoch 194/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0734 - acc: 0.9769 - val_loss: 0.0736 - val_acc: 0.9773\n",
            "Epoch 195/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0732 - acc: 0.9770 - val_loss: 0.0718 - val_acc: 0.9777\n",
            "Epoch 196/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0737 - acc: 0.9773 - val_loss: 0.0739 - val_acc: 0.9775\n",
            "Epoch 197/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0735 - acc: 0.9766 - val_loss: 0.0745 - val_acc: 0.9772\n",
            "Epoch 198/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0730 - acc: 0.9776 - val_loss: 0.0710 - val_acc: 0.9776\n",
            "Epoch 199/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0732 - acc: 0.9769 - val_loss: 0.0758 - val_acc: 0.9769\n",
            "Epoch 200/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0737 - acc: 0.9768 - val_loss: 0.0729 - val_acc: 0.9778\n",
            "Epoch 201/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0729 - acc: 0.9768 - val_loss: 0.0711 - val_acc: 0.9777\n",
            "Epoch 202/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0729 - acc: 0.9774 - val_loss: 0.0735 - val_acc: 0.9776\n",
            "Epoch 203/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0731 - acc: 0.9771 - val_loss: 0.0713 - val_acc: 0.9784\n",
            "Epoch 204/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0731 - acc: 0.9774 - val_loss: 0.0712 - val_acc: 0.9780\n",
            "Epoch 205/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0732 - acc: 0.9772 - val_loss: 0.0745 - val_acc: 0.9773\n",
            "Epoch 206/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0738 - acc: 0.9768 - val_loss: 0.0762 - val_acc: 0.9770\n",
            "Epoch 207/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0729 - acc: 0.9775 - val_loss: 0.0712 - val_acc: 0.9783\n",
            "Epoch 208/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0724 - acc: 0.9769 - val_loss: 0.0709 - val_acc: 0.9779\n",
            "Epoch 209/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0731 - acc: 0.9767 - val_loss: 0.0711 - val_acc: 0.9784\n",
            "Epoch 210/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0725 - acc: 0.9776 - val_loss: 0.0721 - val_acc: 0.9778\n",
            "Epoch 211/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0730 - acc: 0.9768 - val_loss: 0.0716 - val_acc: 0.9783\n",
            "Epoch 212/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0731 - acc: 0.9774 - val_loss: 0.0744 - val_acc: 0.9771\n",
            "Epoch 213/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0728 - acc: 0.9769 - val_loss: 0.0740 - val_acc: 0.9774\n",
            "Epoch 214/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0733 - acc: 0.9774 - val_loss: 0.0735 - val_acc: 0.9779\n",
            "Epoch 215/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0725 - acc: 0.9772 - val_loss: 0.0697 - val_acc: 0.9790\n",
            "Epoch 216/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0727 - acc: 0.9775 - val_loss: 0.0728 - val_acc: 0.9782\n",
            "Epoch 217/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0726 - acc: 0.9770 - val_loss: 0.0738 - val_acc: 0.9774\n",
            "Epoch 218/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0725 - acc: 0.9773 - val_loss: 0.0744 - val_acc: 0.9776\n",
            "Epoch 219/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0731 - acc: 0.9772 - val_loss: 0.0702 - val_acc: 0.9786\n",
            "Epoch 220/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0722 - acc: 0.9772 - val_loss: 0.0742 - val_acc: 0.9760\n",
            "Epoch 221/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0726 - acc: 0.9773 - val_loss: 0.0713 - val_acc: 0.9782\n",
            "Epoch 222/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0720 - acc: 0.9773 - val_loss: 0.0720 - val_acc: 0.9782\n",
            "Epoch 223/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0721 - acc: 0.9771 - val_loss: 0.0722 - val_acc: 0.9778\n",
            "Epoch 224/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0729 - acc: 0.9774 - val_loss: 0.0699 - val_acc: 0.9783\n",
            "Epoch 225/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0724 - acc: 0.9775 - val_loss: 0.0753 - val_acc: 0.9780\n",
            "Epoch 226/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0722 - acc: 0.9773 - val_loss: 0.0726 - val_acc: 0.9777\n",
            "Epoch 227/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0726 - acc: 0.9770 - val_loss: 0.0707 - val_acc: 0.9779\n",
            "Epoch 228/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0718 - acc: 0.9776 - val_loss: 0.0712 - val_acc: 0.9784\n",
            "Epoch 229/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0720 - acc: 0.9775 - val_loss: 0.0699 - val_acc: 0.9775\n",
            "Epoch 230/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0717 - acc: 0.9778 - val_loss: 0.0733 - val_acc: 0.9785\n",
            "Epoch 231/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0730 - acc: 0.9773 - val_loss: 0.0771 - val_acc: 0.9762\n",
            "Epoch 232/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0723 - acc: 0.9776 - val_loss: 0.0723 - val_acc: 0.9783\n",
            "Epoch 233/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0727 - acc: 0.9765 - val_loss: 0.0704 - val_acc: 0.9774\n",
            "Epoch 234/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0720 - acc: 0.9775 - val_loss: 0.0716 - val_acc: 0.9776\n",
            "Epoch 235/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0720 - acc: 0.9776 - val_loss: 0.0701 - val_acc: 0.9785\n",
            "Epoch 236/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0726 - acc: 0.9774 - val_loss: 0.0725 - val_acc: 0.9779\n",
            "Epoch 237/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0721 - acc: 0.9771 - val_loss: 0.0707 - val_acc: 0.9779\n",
            "Epoch 238/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0720 - acc: 0.9770 - val_loss: 0.0709 - val_acc: 0.9778\n",
            "Epoch 239/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0724 - acc: 0.9767 - val_loss: 0.0744 - val_acc: 0.9771\n",
            "Epoch 240/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0722 - acc: 0.9775 - val_loss: 0.0746 - val_acc: 0.9770\n",
            "Epoch 241/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0720 - acc: 0.9777 - val_loss: 0.0774 - val_acc: 0.9772\n",
            "Epoch 242/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0721 - acc: 0.9772 - val_loss: 0.0708 - val_acc: 0.9781\n",
            "Epoch 243/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0722 - acc: 0.9776 - val_loss: 0.0693 - val_acc: 0.9784\n",
            "Epoch 244/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0716 - acc: 0.9772 - val_loss: 0.0723 - val_acc: 0.9777\n",
            "Epoch 245/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0719 - acc: 0.9772 - val_loss: 0.0757 - val_acc: 0.9771\n",
            "Epoch 246/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0726 - acc: 0.9773 - val_loss: 0.0778 - val_acc: 0.9767\n",
            "Epoch 247/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0726 - acc: 0.9772 - val_loss: 0.0734 - val_acc: 0.9777\n",
            "Epoch 248/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0718 - acc: 0.9781 - val_loss: 0.0709 - val_acc: 0.9774\n",
            "Epoch 249/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0716 - acc: 0.9775 - val_loss: 0.0710 - val_acc: 0.9787\n",
            "Epoch 250/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0719 - acc: 0.9773 - val_loss: 0.0740 - val_acc: 0.9772\n",
            "Epoch 251/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0719 - acc: 0.9771 - val_loss: 0.0762 - val_acc: 0.9772\n",
            "Epoch 252/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0715 - acc: 0.9776 - val_loss: 0.0704 - val_acc: 0.9783\n",
            "Epoch 253/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0717 - acc: 0.9775 - val_loss: 0.0724 - val_acc: 0.9772\n",
            "Epoch 254/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - acc: 0.9776 - val_loss: 0.0712 - val_acc: 0.9781\n",
            "Epoch 255/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0716 - acc: 0.9777 - val_loss: 0.0706 - val_acc: 0.9783\n",
            "Epoch 256/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0717 - acc: 0.9774 - val_loss: 0.0743 - val_acc: 0.9766\n",
            "Epoch 257/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0717 - acc: 0.9774 - val_loss: 0.0710 - val_acc: 0.9780\n",
            "Epoch 258/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0719 - acc: 0.9774 - val_loss: 0.0747 - val_acc: 0.9776\n",
            "Epoch 259/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0715 - acc: 0.9776 - val_loss: 0.0711 - val_acc: 0.9783\n",
            "Epoch 260/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0717 - acc: 0.9781 - val_loss: 0.0698 - val_acc: 0.9775\n",
            "Epoch 261/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0716 - acc: 0.9774 - val_loss: 0.0786 - val_acc: 0.9762\n",
            "Epoch 262/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0711 - acc: 0.9774 - val_loss: 0.0703 - val_acc: 0.9789\n",
            "Epoch 263/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0712 - acc: 0.9777 - val_loss: 0.0719 - val_acc: 0.9777\n",
            "Epoch 264/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0718 - acc: 0.9776 - val_loss: 0.0721 - val_acc: 0.9772\n",
            "Epoch 265/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0719 - acc: 0.9775 - val_loss: 0.0775 - val_acc: 0.9762\n",
            "Epoch 266/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0711 - acc: 0.9776 - val_loss: 0.0772 - val_acc: 0.9765\n",
            "Epoch 267/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0720 - acc: 0.9777 - val_loss: 0.0733 - val_acc: 0.9772\n",
            "Epoch 268/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0711 - acc: 0.9771 - val_loss: 0.0775 - val_acc: 0.9771\n",
            "Epoch 269/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0715 - acc: 0.9776 - val_loss: 0.0723 - val_acc: 0.9783\n",
            "Epoch 270/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - acc: 0.9777 - val_loss: 0.0706 - val_acc: 0.9784\n",
            "Epoch 271/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0717 - acc: 0.9776 - val_loss: 0.0708 - val_acc: 0.9785\n",
            "Epoch 272/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0711 - acc: 0.9775 - val_loss: 0.0705 - val_acc: 0.9787\n",
            "Epoch 273/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0711 - acc: 0.9778 - val_loss: 0.0720 - val_acc: 0.9780\n",
            "Epoch 274/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0715 - acc: 0.9772 - val_loss: 0.0720 - val_acc: 0.9781\n",
            "Epoch 275/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0718 - acc: 0.9776 - val_loss: 0.0709 - val_acc: 0.9785\n",
            "Epoch 276/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0716 - acc: 0.9772 - val_loss: 0.0740 - val_acc: 0.9776\n",
            "Epoch 277/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0712 - acc: 0.9772 - val_loss: 0.0703 - val_acc: 0.9779\n",
            "Epoch 278/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0712 - acc: 0.9779 - val_loss: 0.0724 - val_acc: 0.9776\n",
            "Epoch 279/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0707 - acc: 0.9779 - val_loss: 0.0715 - val_acc: 0.9777\n",
            "Epoch 280/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - acc: 0.9775 - val_loss: 0.0695 - val_acc: 0.9781\n",
            "Epoch 281/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0708 - acc: 0.9775 - val_loss: 0.0711 - val_acc: 0.9780\n",
            "Epoch 282/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - acc: 0.9771 - val_loss: 0.0712 - val_acc: 0.9780\n",
            "Epoch 283/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0712 - acc: 0.9772 - val_loss: 0.0727 - val_acc: 0.9787\n",
            "Epoch 284/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - acc: 0.9778 - val_loss: 0.0702 - val_acc: 0.9781\n",
            "Epoch 285/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0710 - acc: 0.9776 - val_loss: 0.0729 - val_acc: 0.9773\n",
            "Epoch 286/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0711 - acc: 0.9774 - val_loss: 0.0753 - val_acc: 0.9763\n",
            "Epoch 287/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0709 - acc: 0.9774 - val_loss: 0.0698 - val_acc: 0.9777\n",
            "Epoch 288/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0712 - acc: 0.9774 - val_loss: 0.0737 - val_acc: 0.9777\n",
            "Epoch 289/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0716 - acc: 0.9775 - val_loss: 0.0706 - val_acc: 0.9779\n",
            "Epoch 290/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0712 - acc: 0.9778 - val_loss: 0.0728 - val_acc: 0.9780\n",
            "Epoch 291/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0709 - acc: 0.9771 - val_loss: 0.0704 - val_acc: 0.9779\n",
            "Epoch 292/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0718 - acc: 0.9777 - val_loss: 0.0733 - val_acc: 0.9774\n",
            "Epoch 293/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0711 - acc: 0.9777 - val_loss: 0.0787 - val_acc: 0.9759\n",
            "Epoch 294/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0715 - acc: 0.9779 - val_loss: 0.0710 - val_acc: 0.9783\n",
            "Epoch 295/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0719 - acc: 0.9769 - val_loss: 0.0707 - val_acc: 0.9787\n",
            "Epoch 296/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0703 - acc: 0.9779 - val_loss: 0.0733 - val_acc: 0.9766\n",
            "Epoch 297/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0711 - acc: 0.9778 - val_loss: 0.0699 - val_acc: 0.9781\n",
            "Epoch 298/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0713 - acc: 0.9778 - val_loss: 0.0710 - val_acc: 0.9787\n",
            "Epoch 299/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0706 - acc: 0.9779 - val_loss: 0.0720 - val_acc: 0.9787\n",
            "Epoch 300/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0707 - acc: 0.9775 - val_loss: 0.0706 - val_acc: 0.9789\n",
            "Epoch 301/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0715 - acc: 0.9772 - val_loss: 0.0790 - val_acc: 0.9757\n",
            "Epoch 302/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0719 - acc: 0.9778 - val_loss: 0.0709 - val_acc: 0.9779\n",
            "Epoch 303/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0706 - acc: 0.9779 - val_loss: 0.0746 - val_acc: 0.9771\n",
            "Epoch 304/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0716 - acc: 0.9780 - val_loss: 0.0724 - val_acc: 0.9781\n",
            "Epoch 305/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0712 - acc: 0.9777 - val_loss: 0.0704 - val_acc: 0.9778\n",
            "Epoch 306/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0707 - acc: 0.9774 - val_loss: 0.0774 - val_acc: 0.9767\n",
            "Epoch 307/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0701 - acc: 0.9780 - val_loss: 0.0733 - val_acc: 0.9789\n",
            "Epoch 308/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0711 - acc: 0.9774 - val_loss: 0.0701 - val_acc: 0.9781\n",
            "Epoch 309/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0704 - acc: 0.9782 - val_loss: 0.0704 - val_acc: 0.9778\n",
            "Epoch 310/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0712 - acc: 0.9778 - val_loss: 0.0707 - val_acc: 0.9785\n",
            "Epoch 311/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0710 - acc: 0.9778 - val_loss: 0.0706 - val_acc: 0.9781\n",
            "Epoch 312/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0706 - acc: 0.9776 - val_loss: 0.0736 - val_acc: 0.9772\n",
            "Epoch 313/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0708 - acc: 0.9774 - val_loss: 0.0742 - val_acc: 0.9776\n",
            "Epoch 314/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0702 - acc: 0.9780 - val_loss: 0.0720 - val_acc: 0.9783\n",
            "Epoch 315/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0711 - acc: 0.9779 - val_loss: 0.0748 - val_acc: 0.9779\n",
            "Epoch 316/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0706 - acc: 0.9783 - val_loss: 0.0722 - val_acc: 0.9784\n",
            "Epoch 317/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0711 - acc: 0.9778 - val_loss: 0.0712 - val_acc: 0.9788\n",
            "Epoch 318/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0707 - acc: 0.9778 - val_loss: 0.0697 - val_acc: 0.9786\n",
            "Epoch 319/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0707 - acc: 0.9777 - val_loss: 0.0715 - val_acc: 0.9787\n",
            "Epoch 320/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0707 - acc: 0.9777 - val_loss: 0.0695 - val_acc: 0.9790\n",
            "Epoch 321/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0707 - acc: 0.9778 - val_loss: 0.0694 - val_acc: 0.9785\n",
            "Epoch 322/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0704 - acc: 0.9782 - val_loss: 0.0738 - val_acc: 0.9767\n",
            "Epoch 323/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0710 - acc: 0.9774 - val_loss: 0.0767 - val_acc: 0.9761\n",
            "Epoch 324/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0701 - acc: 0.9776 - val_loss: 0.0740 - val_acc: 0.9777\n",
            "Epoch 325/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0710 - acc: 0.9773 - val_loss: 0.0715 - val_acc: 0.9782\n",
            "Epoch 326/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0703 - acc: 0.9777 - val_loss: 0.0757 - val_acc: 0.9762\n",
            "Epoch 327/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0708 - acc: 0.9775 - val_loss: 0.0728 - val_acc: 0.9766\n",
            "Epoch 328/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0705 - acc: 0.9774 - val_loss: 0.0724 - val_acc: 0.9771\n",
            "Epoch 329/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0703 - acc: 0.9777 - val_loss: 0.0712 - val_acc: 0.9775\n",
            "Epoch 330/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0701 - acc: 0.9775 - val_loss: 0.0752 - val_acc: 0.9770\n",
            "Epoch 331/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0706 - acc: 0.9778 - val_loss: 0.0721 - val_acc: 0.9784\n",
            "Epoch 332/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0705 - acc: 0.9778 - val_loss: 0.0716 - val_acc: 0.9771\n",
            "Epoch 333/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0710 - acc: 0.9774 - val_loss: 0.0714 - val_acc: 0.9780\n",
            "Epoch 334/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0707 - acc: 0.9779 - val_loss: 0.0766 - val_acc: 0.9767\n",
            "Epoch 335/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0708 - acc: 0.9776 - val_loss: 0.0715 - val_acc: 0.9777\n",
            "Epoch 336/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0700 - acc: 0.9778 - val_loss: 0.0721 - val_acc: 0.9770\n",
            "Epoch 337/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0702 - acc: 0.9779 - val_loss: 0.0804 - val_acc: 0.9739\n",
            "Epoch 338/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0705 - acc: 0.9771 - val_loss: 0.0706 - val_acc: 0.9779\n",
            "Epoch 339/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0701 - acc: 0.9781 - val_loss: 0.0750 - val_acc: 0.9771\n",
            "Epoch 340/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0704 - acc: 0.9778 - val_loss: 0.0718 - val_acc: 0.9774\n",
            "Epoch 341/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0706 - acc: 0.9778 - val_loss: 0.0697 - val_acc: 0.9789\n",
            "Epoch 342/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0705 - acc: 0.9776 - val_loss: 0.0691 - val_acc: 0.9789\n",
            "Epoch 343/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0706 - acc: 0.9778 - val_loss: 0.0700 - val_acc: 0.9780\n",
            "Epoch 344/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0706 - acc: 0.9778 - val_loss: 0.0789 - val_acc: 0.9766\n",
            "Epoch 345/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0699 - acc: 0.9779 - val_loss: 0.0700 - val_acc: 0.9779\n",
            "Epoch 346/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0708 - acc: 0.9779 - val_loss: 0.0709 - val_acc: 0.9784\n",
            "Epoch 347/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0697 - acc: 0.9780 - val_loss: 0.0749 - val_acc: 0.9765\n",
            "Epoch 348/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0706 - acc: 0.9779 - val_loss: 0.0699 - val_acc: 0.9791\n",
            "Epoch 349/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0705 - acc: 0.9779 - val_loss: 0.0746 - val_acc: 0.9762\n",
            "Epoch 350/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0700 - acc: 0.9778 - val_loss: 0.0773 - val_acc: 0.9771\n",
            "Epoch 351/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0703 - acc: 0.9780 - val_loss: 0.0701 - val_acc: 0.9779\n",
            "Epoch 352/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0701 - acc: 0.9781 - val_loss: 0.0717 - val_acc: 0.9777\n",
            "Epoch 353/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0703 - acc: 0.9783 - val_loss: 0.0735 - val_acc: 0.9767\n",
            "Epoch 354/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0698 - acc: 0.9777 - val_loss: 0.0728 - val_acc: 0.9781\n",
            "Epoch 355/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0707 - acc: 0.9779 - val_loss: 0.0741 - val_acc: 0.9782\n",
            "Epoch 356/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0701 - acc: 0.9780 - val_loss: 0.0727 - val_acc: 0.9786\n",
            "Epoch 357/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0700 - acc: 0.9778 - val_loss: 0.0703 - val_acc: 0.9787\n",
            "Epoch 358/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0704 - acc: 0.9780 - val_loss: 0.0701 - val_acc: 0.9785\n",
            "Epoch 359/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0702 - acc: 0.9774 - val_loss: 0.0722 - val_acc: 0.9791\n",
            "Epoch 360/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0703 - acc: 0.9782 - val_loss: 0.0751 - val_acc: 0.9776\n",
            "Epoch 361/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0695 - acc: 0.9780 - val_loss: 0.0750 - val_acc: 0.9773\n",
            "Epoch 362/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0708 - acc: 0.9770 - val_loss: 0.0727 - val_acc: 0.9772\n",
            "Epoch 363/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0697 - acc: 0.9781 - val_loss: 0.0726 - val_acc: 0.9776\n",
            "Epoch 364/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0705 - acc: 0.9779 - val_loss: 0.0758 - val_acc: 0.9762\n",
            "Epoch 365/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0705 - acc: 0.9778 - val_loss: 0.0710 - val_acc: 0.9777\n",
            "Epoch 366/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0702 - acc: 0.9778 - val_loss: 0.0735 - val_acc: 0.9778\n",
            "Epoch 367/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0711 - acc: 0.9775 - val_loss: 0.0729 - val_acc: 0.9772\n",
            "Epoch 368/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0697 - acc: 0.9786 - val_loss: 0.0742 - val_acc: 0.9762\n",
            "Epoch 369/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0700 - acc: 0.9782 - val_loss: 0.0716 - val_acc: 0.9770\n",
            "Epoch 370/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0702 - acc: 0.9780 - val_loss: 0.0722 - val_acc: 0.9781\n",
            "Epoch 371/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0707 - acc: 0.9778 - val_loss: 0.0730 - val_acc: 0.9775\n",
            "Epoch 372/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0705 - acc: 0.9779 - val_loss: 0.0764 - val_acc: 0.9776\n",
            "Epoch 373/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0699 - acc: 0.9778 - val_loss: 0.0705 - val_acc: 0.9780\n",
            "Epoch 374/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0699 - acc: 0.9780 - val_loss: 0.0733 - val_acc: 0.9777\n",
            "Epoch 375/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0697 - acc: 0.9778 - val_loss: 0.0743 - val_acc: 0.9763\n",
            "Epoch 376/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0702 - acc: 0.9782 - val_loss: 0.0727 - val_acc: 0.9780\n",
            "Epoch 377/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0700 - acc: 0.9781 - val_loss: 0.0803 - val_acc: 0.9744\n",
            "Epoch 378/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0699 - acc: 0.9779 - val_loss: 0.0718 - val_acc: 0.9784\n",
            "Epoch 379/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0703 - acc: 0.9780 - val_loss: 0.0714 - val_acc: 0.9780\n",
            "Epoch 380/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0697 - acc: 0.9775 - val_loss: 0.0761 - val_acc: 0.9773\n",
            "Epoch 381/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0701 - acc: 0.9783 - val_loss: 0.0713 - val_acc: 0.9779\n",
            "Epoch 382/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0694 - acc: 0.9787 - val_loss: 0.0713 - val_acc: 0.9784\n",
            "Epoch 383/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0700 - acc: 0.9775 - val_loss: 0.0696 - val_acc: 0.9782\n",
            "Epoch 384/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0701 - acc: 0.9780 - val_loss: 0.0746 - val_acc: 0.9773\n",
            "Epoch 385/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0696 - acc: 0.9780 - val_loss: 0.0701 - val_acc: 0.9782\n",
            "Epoch 386/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0699 - acc: 0.9781 - val_loss: 0.0722 - val_acc: 0.9777\n",
            "Epoch 387/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0695 - acc: 0.9783 - val_loss: 0.0707 - val_acc: 0.9786\n",
            "Epoch 388/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0698 - acc: 0.9776 - val_loss: 0.0729 - val_acc: 0.9782\n",
            "Epoch 389/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0701 - acc: 0.9777 - val_loss: 0.0692 - val_acc: 0.9779\n",
            "Epoch 390/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0706 - acc: 0.9779 - val_loss: 0.0698 - val_acc: 0.9780\n",
            "Epoch 391/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0701 - acc: 0.9783 - val_loss: 0.0707 - val_acc: 0.9792\n",
            "Epoch 392/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0697 - acc: 0.9784 - val_loss: 0.0700 - val_acc: 0.9784\n",
            "Epoch 393/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0699 - acc: 0.9784 - val_loss: 0.0682 - val_acc: 0.9795\n",
            "Epoch 394/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0699 - acc: 0.9782 - val_loss: 0.0695 - val_acc: 0.9786\n",
            "Epoch 395/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0694 - acc: 0.9779 - val_loss: 0.0704 - val_acc: 0.9786\n",
            "Epoch 396/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0698 - acc: 0.9784 - val_loss: 0.0720 - val_acc: 0.9774\n",
            "Epoch 397/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0699 - acc: 0.9775 - val_loss: 0.0716 - val_acc: 0.9781\n",
            "Epoch 398/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0694 - acc: 0.9783 - val_loss: 0.0742 - val_acc: 0.9777\n",
            "Epoch 399/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0703 - acc: 0.9781 - val_loss: 0.0695 - val_acc: 0.9784\n",
            "Epoch 400/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0693 - acc: 0.9777 - val_loss: 0.0737 - val_acc: 0.9769\n",
            "Epoch 401/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0698 - acc: 0.9780 - val_loss: 0.0699 - val_acc: 0.9782\n",
            "Epoch 402/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0699 - acc: 0.9780 - val_loss: 0.0715 - val_acc: 0.9783\n",
            "Epoch 403/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0696 - acc: 0.9784 - val_loss: 0.0692 - val_acc: 0.9789\n",
            "Epoch 404/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0692 - acc: 0.9781 - val_loss: 0.0723 - val_acc: 0.9785\n",
            "Epoch 405/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0694 - acc: 0.9783 - val_loss: 0.0729 - val_acc: 0.9776\n",
            "Epoch 406/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0692 - acc: 0.9781 - val_loss: 0.0732 - val_acc: 0.9778\n",
            "Epoch 407/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0694 - acc: 0.9779 - val_loss: 0.0702 - val_acc: 0.9785\n",
            "Epoch 408/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0700 - acc: 0.9785 - val_loss: 0.0726 - val_acc: 0.9771\n",
            "Epoch 409/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0695 - acc: 0.9784 - val_loss: 0.0730 - val_acc: 0.9788\n",
            "Epoch 410/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0695 - acc: 0.9779 - val_loss: 0.0702 - val_acc: 0.9772\n",
            "Epoch 411/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0701 - acc: 0.9779 - val_loss: 0.0705 - val_acc: 0.9782\n",
            "Epoch 412/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0693 - acc: 0.9782 - val_loss: 0.0726 - val_acc: 0.9776\n",
            "Epoch 413/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0695 - acc: 0.9783 - val_loss: 0.0712 - val_acc: 0.9783\n",
            "Epoch 414/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0697 - acc: 0.9783 - val_loss: 0.0696 - val_acc: 0.9781\n",
            "Epoch 415/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0694 - acc: 0.9780 - val_loss: 0.0721 - val_acc: 0.9786\n",
            "Epoch 416/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0692 - acc: 0.9782 - val_loss: 0.0728 - val_acc: 0.9775\n",
            "Epoch 417/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0697 - acc: 0.9778 - val_loss: 0.0690 - val_acc: 0.9791\n",
            "Epoch 418/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0696 - acc: 0.9779 - val_loss: 0.0717 - val_acc: 0.9780\n",
            "Epoch 419/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0690 - acc: 0.9784 - val_loss: 0.0718 - val_acc: 0.9783\n",
            "Epoch 420/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0702 - acc: 0.9784 - val_loss: 0.0742 - val_acc: 0.9779\n",
            "Epoch 421/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0694 - acc: 0.9778 - val_loss: 0.0708 - val_acc: 0.9785\n",
            "Epoch 422/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0692 - acc: 0.9781 - val_loss: 0.0724 - val_acc: 0.9777\n",
            "Epoch 423/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0694 - acc: 0.9778 - val_loss: 0.0712 - val_acc: 0.9781\n",
            "Epoch 424/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0697 - acc: 0.9779 - val_loss: 0.0728 - val_acc: 0.9780\n",
            "Epoch 425/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0690 - acc: 0.9780 - val_loss: 0.0707 - val_acc: 0.9792\n",
            "Epoch 426/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0691 - acc: 0.9786 - val_loss: 0.0710 - val_acc: 0.9787\n",
            "Epoch 427/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0693 - acc: 0.9782 - val_loss: 0.0718 - val_acc: 0.9786\n",
            "Epoch 428/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0696 - acc: 0.9780 - val_loss: 0.0713 - val_acc: 0.9776\n",
            "Epoch 429/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0696 - acc: 0.9780 - val_loss: 0.0711 - val_acc: 0.9776\n",
            "Epoch 430/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0694 - acc: 0.9780 - val_loss: 0.0823 - val_acc: 0.9761\n",
            "Epoch 431/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0697 - acc: 0.9786 - val_loss: 0.0710 - val_acc: 0.9783\n",
            "Epoch 432/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0696 - acc: 0.9779 - val_loss: 0.0754 - val_acc: 0.9762\n",
            "Epoch 433/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0693 - acc: 0.9781 - val_loss: 0.0729 - val_acc: 0.9782\n",
            "Epoch 434/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0689 - acc: 0.9779 - val_loss: 0.0718 - val_acc: 0.9787\n",
            "Epoch 435/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0693 - acc: 0.9783 - val_loss: 0.0737 - val_acc: 0.9770\n",
            "Epoch 436/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0694 - acc: 0.9785 - val_loss: 0.0740 - val_acc: 0.9775\n",
            "Epoch 437/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0694 - acc: 0.9784 - val_loss: 0.0690 - val_acc: 0.9791\n",
            "Epoch 438/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0688 - acc: 0.9786 - val_loss: 0.0764 - val_acc: 0.9755\n",
            "Epoch 439/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0694 - acc: 0.9781 - val_loss: 0.0734 - val_acc: 0.9786\n",
            "Epoch 440/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0692 - acc: 0.9788 - val_loss: 0.0739 - val_acc: 0.9778\n",
            "Epoch 441/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0695 - acc: 0.9779 - val_loss: 0.0722 - val_acc: 0.9781\n",
            "Epoch 442/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0695 - acc: 0.9779 - val_loss: 0.0694 - val_acc: 0.9786\n",
            "Epoch 443/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0688 - acc: 0.9786 - val_loss: 0.0718 - val_acc: 0.9775\n",
            "Epoch 444/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0700 - acc: 0.9777 - val_loss: 0.0834 - val_acc: 0.9733\n",
            "Epoch 445/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0693 - acc: 0.9786 - val_loss: 0.0726 - val_acc: 0.9774\n",
            "Epoch 446/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0688 - acc: 0.9783 - val_loss: 0.0720 - val_acc: 0.9784\n",
            "Epoch 447/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0691 - acc: 0.9786 - val_loss: 0.0708 - val_acc: 0.9779\n",
            "Epoch 448/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0695 - acc: 0.9783 - val_loss: 0.0689 - val_acc: 0.9794\n",
            "Epoch 449/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0690 - acc: 0.9785 - val_loss: 0.0765 - val_acc: 0.9763\n",
            "Epoch 450/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0696 - acc: 0.9781 - val_loss: 0.0707 - val_acc: 0.9786\n",
            "Epoch 451/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0691 - acc: 0.9782 - val_loss: 0.0690 - val_acc: 0.9785\n",
            "Epoch 452/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0696 - acc: 0.9786 - val_loss: 0.0701 - val_acc: 0.9776\n",
            "Epoch 453/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0688 - acc: 0.9780 - val_loss: 0.0708 - val_acc: 0.9790\n",
            "Epoch 454/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0690 - acc: 0.9788 - val_loss: 0.0719 - val_acc: 0.9776\n",
            "Epoch 455/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0691 - acc: 0.9787 - val_loss: 0.0877 - val_acc: 0.9738\n",
            "Epoch 456/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0700 - acc: 0.9776 - val_loss: 0.0732 - val_acc: 0.9776\n",
            "Epoch 457/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0690 - acc: 0.9783 - val_loss: 0.0741 - val_acc: 0.9771\n",
            "Epoch 458/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0698 - acc: 0.9779 - val_loss: 0.0707 - val_acc: 0.9780\n",
            "Epoch 459/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0698 - acc: 0.9779 - val_loss: 0.0719 - val_acc: 0.9781\n",
            "Epoch 460/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0694 - acc: 0.9786 - val_loss: 0.0730 - val_acc: 0.9771\n",
            "Epoch 461/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0692 - acc: 0.9780 - val_loss: 0.0695 - val_acc: 0.9789\n",
            "Epoch 462/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0693 - acc: 0.9782 - val_loss: 0.0723 - val_acc: 0.9775\n",
            "Epoch 463/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0689 - acc: 0.9782 - val_loss: 0.0691 - val_acc: 0.9782\n",
            "Epoch 464/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0690 - acc: 0.9784 - val_loss: 0.0710 - val_acc: 0.9781\n",
            "Epoch 465/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0691 - acc: 0.9784 - val_loss: 0.0696 - val_acc: 0.9784\n",
            "Epoch 466/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0691 - acc: 0.9789 - val_loss: 0.0711 - val_acc: 0.9785\n",
            "Epoch 467/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0693 - acc: 0.9780 - val_loss: 0.0740 - val_acc: 0.9773\n",
            "Epoch 468/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0687 - acc: 0.9785 - val_loss: 0.0705 - val_acc: 0.9789\n",
            "Epoch 469/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0694 - acc: 0.9780 - val_loss: 0.0820 - val_acc: 0.9757\n",
            "Epoch 470/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0694 - acc: 0.9780 - val_loss: 0.0718 - val_acc: 0.9783\n",
            "Epoch 471/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0691 - acc: 0.9783 - val_loss: 0.0764 - val_acc: 0.9769\n",
            "Epoch 472/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0688 - acc: 0.9783 - val_loss: 0.0707 - val_acc: 0.9773\n",
            "Epoch 473/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0694 - acc: 0.9776 - val_loss: 0.0711 - val_acc: 0.9787\n",
            "Epoch 474/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0690 - acc: 0.9784 - val_loss: 0.0700 - val_acc: 0.9791\n",
            "Epoch 475/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0694 - acc: 0.9781 - val_loss: 0.0701 - val_acc: 0.9785\n",
            "Epoch 476/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0685 - acc: 0.9784 - val_loss: 0.0711 - val_acc: 0.9785\n",
            "Epoch 477/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0698 - acc: 0.9782 - val_loss: 0.0710 - val_acc: 0.9776\n",
            "Epoch 478/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0686 - acc: 0.9785 - val_loss: 0.0735 - val_acc: 0.9772\n",
            "Epoch 479/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0691 - acc: 0.9781 - val_loss: 0.0704 - val_acc: 0.9776\n",
            "Epoch 480/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0684 - acc: 0.9789 - val_loss: 0.0711 - val_acc: 0.9783\n",
            "Epoch 481/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0692 - acc: 0.9782 - val_loss: 0.0714 - val_acc: 0.9784\n",
            "Epoch 482/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0693 - acc: 0.9783 - val_loss: 0.0702 - val_acc: 0.9785\n",
            "Epoch 483/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0687 - acc: 0.9782 - val_loss: 0.0697 - val_acc: 0.9785\n",
            "Epoch 484/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0690 - acc: 0.9779 - val_loss: 0.0699 - val_acc: 0.9792\n",
            "Epoch 485/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0697 - acc: 0.9780 - val_loss: 0.0725 - val_acc: 0.9778\n",
            "Epoch 486/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0692 - acc: 0.9783 - val_loss: 0.0707 - val_acc: 0.9778\n",
            "Epoch 487/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0693 - acc: 0.9782 - val_loss: 0.0712 - val_acc: 0.9775\n",
            "Epoch 488/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0695 - acc: 0.9784 - val_loss: 0.0699 - val_acc: 0.9789\n",
            "Epoch 489/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0694 - acc: 0.9779 - val_loss: 0.0691 - val_acc: 0.9792\n",
            "Epoch 490/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0690 - acc: 0.9788 - val_loss: 0.0735 - val_acc: 0.9778\n",
            "Epoch 491/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0693 - acc: 0.9783 - val_loss: 0.0741 - val_acc: 0.9771\n",
            "Epoch 492/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0690 - acc: 0.9784 - val_loss: 0.0748 - val_acc: 0.9767\n",
            "Epoch 493/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0687 - acc: 0.9784 - val_loss: 0.0707 - val_acc: 0.9791\n",
            "Epoch 494/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0685 - acc: 0.9789 - val_loss: 0.0704 - val_acc: 0.9776\n",
            "Epoch 495/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0685 - acc: 0.9782 - val_loss: 0.0710 - val_acc: 0.9786\n",
            "Epoch 496/500\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0692 - acc: 0.9786 - val_loss: 0.0686 - val_acc: 0.9779\n",
            "Epoch 497/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0691 - acc: 0.9786 - val_loss: 0.0702 - val_acc: 0.9788\n",
            "Epoch 498/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0694 - acc: 0.9778 - val_loss: 0.0734 - val_acc: 0.9775\n",
            "Epoch 499/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0691 - acc: 0.9786 - val_loss: 0.0699 - val_acc: 0.9788\n",
            "Epoch 500/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0691 - acc: 0.9780 - val_loss: 0.0728 - val_acc: 0.9779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model_cnn.evaluate(test_img , test_labels , verbose = 1)\n",
        "print('정답률=', score[1], 'loss=',score[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKR5tDl4QV-7",
        "outputId": "a9cceda9-711a-4f2c-b958-30928a68a8b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0728 - acc: 0.9779\n",
            "정답률= 0.9779000282287598 loss= 0.07277760654687881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDHGIk2ibN1e",
        "outputId": "42e840d4-c263-4307-aa58-5b7908f2a5c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "fig = plt.figure(figsize = (10,5))\n",
        "\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax1.plot(epochs, loss, color='blue', label = 'train_loss')\n",
        "ax1.plot(epochs, val_loss, color='orange' , label = 'val_loss')\n",
        "ax1.set_title('train_val loss')\n",
        "ax1.set_xlabel('epochs')\n",
        "ax1.set_ylabel('loss')\n",
        "ax1.legend()\n",
        "\n",
        "acc = hist.history['acc']\n",
        "val_acc = hist.history['val_acc']\n",
        "\n",
        "ax1 = fig.add_subplot(1,2,2)\n",
        "ax1.plot(epochs, acc, color='blue', label = 'train_acc')\n",
        "ax1.plot(epochs, val_acc, color='orange' , label = 'val_acc')\n",
        "ax1.set_title('train_val acc')\n",
        "ax1.set_xlabel('epochs')\n",
        "ax1.set_ylabel('acc')\n",
        "ax1.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "s1jQ5JHHbdj1",
        "outputId": "a91968c3-038f-4792-a372-2443c0a88be2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa160591b50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aeXu7Z1PcLRV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}